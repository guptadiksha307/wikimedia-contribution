{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext in /srv/paws/lib/python3.6/site-packages\r\n",
      "Requirement already satisfied: numpy in /srv/paws/lib/python3.6/site-packages (from fasttext)\r\n",
      "Requirement already satisfied: pybind11>=2.2 in /srv/paws/lib/python3.6/site-packages (from fasttext)\r\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /srv/paws/lib/python3.6/site-packages (from fasttext)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import fasttext\n",
    "model=fasttext.load_model('model.bin')\n",
    "\n",
    "\n",
    "def qid_to_claims(qid):\n",
    "    \n",
    "    import requests\n",
    "\n",
    "    S = requests.Session()\n",
    "\n",
    "    URL = \"http://www.wikidata.org/w/api.php\"\n",
    "    PARAMS = {\n",
    "    \"action\": \"wbgetentities\",\n",
    "    \"ids\": qid,\n",
    "    \"props\": \"claims\",\n",
    "    \"format\": \"json\"\n",
    "         }\n",
    "\n",
    "    R = S.get(url=URL, params=PARAMS)\n",
    "    DATA = R.json()\n",
    "    dict=DATA['entities'][qid]['claims'].keys()\n",
    "\n",
    "    Claims=[]\n",
    "\n",
    "    for i in dict:\n",
    "         length= len(DATA['entities'][qid]['claims'][i])\n",
    "    \n",
    "         for j in range(0,length):\n",
    "            if('datavalue' in DATA['entities'][qid]['claims'][i][j]['mainsnak'].keys() ):\n",
    "                if(DATA['entities'][qid]['claims'][i][j]['mainsnak']['datavalue']['type']=='wikibase-entityid'):\n",
    "                \n",
    "                    Claims.append(tuple((i, DATA['entities'][qid]['claims'][i][j]['mainsnak']['datavalue']['value']['id'])))\n",
    "            \n",
    "                else:\n",
    "                    Claims.append(tuple((i,\"\")))\n",
    "\n",
    "    return Claims\n",
    "\n",
    "#general function which calculates cosine similarity between two Qids on basis of a particular property id\n",
    "\n",
    "def evaluate_with_specific_pid(qid1,qid2,prop_id): \n",
    "    prop1=qid_to_claims(qid1)\n",
    "    prop2=qid_to_claims(qid2)\n",
    "\n",
    "    embedding1=[]\n",
    "    embedding2=[]\n",
    "    count1=0\n",
    "    count2=0\n",
    "    \n",
    "    for i in range(len(prop1)):\n",
    "        \n",
    "        if(prop1[i][0]==prop_id):\n",
    "                \n",
    "            \n",
    "                \n",
    "            pid=prop1[i][0]\n",
    "            qid=prop1[i][1]\n",
    "        \n",
    "            if count1==0:\n",
    "                embedding1=np.array(model.get_word_vector(pid))\n",
    "            else:\n",
    "                embedding1=np.add(embedding1,np.array(model.get_word_vector(pid)))\n",
    "            count1=count1+1\n",
    "            if qid!='':\n",
    "                embedding1=np.add(embedding1,np.array(model.get_word_vector(qid)))\n",
    "                count1=count1+1\n",
    "    doc_embedding1=np.divide(embedding1,count1) #document embedding of 1st Qid\n",
    "\n",
    "    for i in range(len(prop2)):\n",
    "        if(prop2[i][0]==prop_id):\n",
    "                \n",
    "            pid=prop2[i][0]\n",
    "            qid=prop2[i][1]\n",
    "        \n",
    "            if count2==0:\n",
    "                embedding2=np.array(model.get_word_vector(pid))\n",
    "            else:\n",
    "                embedding2=np.add(embedding2,np.array(model.get_word_vector(pid)))\n",
    "            count2=count2+1\n",
    "            if qid!='':\n",
    "                embedding2=np.add(embedding2,np.array(model.get_word_vector(qid)))\n",
    "                count2=count2+1\n",
    "    doc_embedding2=np.divide(embedding2,count2) #document embedding of 2nd Qid\n",
    "\n",
    "    sq1=0\n",
    "    sq2=0\n",
    "    sum=0\n",
    "    for i in range(50):\n",
    "        sum=sum+(doc_embedding1[i]*doc_embedding2[i])\n",
    "        sq1=sq1+(doc_embedding1[i]**2)\n",
    "        sq2=sq2+(doc_embedding2[i]**2)\n",
    "    sq1=sq1**0.5\n",
    "    sq2=sq2**0.5\n",
    "\n",
    "    cosine_similarity=sum/(sq1*sq2) #comparing 2 document embeddings using cosine similarity\n",
    "\n",
    "    return cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33385809999395466\n"
     ]
    }
   ],
   "source": [
    "#comparing china and india on basis of property-official language(P37)\n",
    "\n",
    "china='Q148'\n",
    "india='Q668'\n",
    "language_pid='P37'\n",
    "\n",
    "print(evaluate_with_specific_pid(china,india,language_pid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21615518430215525\n"
     ]
    }
   ],
   "source": [
    "#comparing greenland and india on basis of property-official language(P37)\n",
    "\n",
    "\n",
    "greenland='Q223'\n",
    "india='Q668'\n",
    "language_pid='P37' \n",
    "\n",
    "print(evaluate_with_specific_pid(greenland,india,language_pid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04471686409846419\n"
     ]
    }
   ],
   "source": [
    "#comparing greenland and italy on basis of property-official language(P37)\n",
    "\n",
    "italy='Q38'\n",
    "greenland='Q223'\n",
    "language_pid='P37' \n",
    "print(evaluate_with_specific_pid(australia,greenland,language_pid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000054191582\n"
     ]
    }
   ],
   "source": [
    "#comparing coronavirus pandemic in italy and US on the basis of number of deaths('P1120')\n",
    "\n",
    "coronavirus_Italy='Q84104992'\n",
    "coronavirus_United_Kingdom='Q84167106'\n",
    "number_of_deaths_pid='P1120' \n",
    "print(evaluate_with_specific_pid(coronavirus_Italy,coronavirus_United_Kingdom,number_of_deaths_pid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('P1120', '')\n",
      "('P1120', '')\n",
      "('P1120', '')\n",
      "('P1120', '')\n",
      "('P1120', '')\n",
      "('P1120', '')\n",
      "('P1120', '')\n",
      "('P1120', '')\n",
      "('P1120', '')\n",
      "('P1120', '')\n",
      "('P1120', '')\n",
      "('P1120', '')\n",
      "('P1120', '')\n",
      "('P1120', '')\n"
     ]
    }
   ],
   "source": [
    "#Reason for getting cosine similarity of above case as '+1' is because no Qids of P1120 are of type wikipedia-entityid.\n",
    "\n",
    "claims=qid_to_claims('Q84167106')\n",
    "for i in claims:\n",
    "    if(i[0]==\"P1120\"):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
