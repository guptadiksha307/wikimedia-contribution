{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fasttext\n",
      "  Using cached https://files.pythonhosted.org/packages/10/61/2e01f1397ec533756c1d893c22d9d5ed3fce3a6e4af1976e0d86bb13ea97/fasttext-0.9.1.tar.gz\n",
      "Requirement already satisfied: numpy in /srv/paws/lib/python3.6/site-packages (from fasttext)\n",
      "Requirement already satisfied: pybind11>=2.2 in /srv/paws/lib/python3.6/site-packages (from fasttext)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /srv/paws/lib/python3.6/site-packages (from fasttext)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Running setup.py bdist_wheel for fasttext ... \u001b[?25lerror\n",
      "  Complete output from command /srv/paws/bin/python3.6 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-u7h5buj1/fasttext/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d /tmp/tmp4cevh2nppip-wheel- --python-tag cp36:\n",
      "  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n",
      "     or: -c --help [cmd1 cmd2 ...]\n",
      "     or: -c --help-commands\n",
      "     or: -c cmd --help\n",
      "  \n",
      "  error: invalid command 'bdist_wheel'\n",
      "  \n",
      "  ----------------------------------------\n",
      "\u001b[31m  Failed building wheel for fasttext\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for fasttext\n",
      "Failed to build fasttext\n",
      "Installing collected packages: fasttext\n",
      "  Running setup.py install for fasttext ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed fasttext-0.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import fasttext\n",
    "model=fasttext.load_model('model.bin')\n",
    "\n",
    "\n",
    "def qid_to_claims(qid):\n",
    "    \n",
    "    import requests\n",
    "\n",
    "    S = requests.Session()\n",
    "\n",
    "    URL = \"http://www.wikidata.org/w/api.php\"\n",
    "    PARAMS = {\n",
    "    \"action\": \"wbgetentities\",\n",
    "    \"ids\": qid,\n",
    "    \"props\": \"claims\",\n",
    "    \"format\": \"json\"\n",
    "         }\n",
    "\n",
    "    R = S.get(url=URL, params=PARAMS)\n",
    "    DATA = R.json()\n",
    "    dict=DATA['entities'][qid]['claims'].keys()\n",
    "\n",
    "    Claims=[]\n",
    "\n",
    "    for i in dict:\n",
    "         length= len(DATA['entities'][qid]['claims'][i])\n",
    "    \n",
    "         for j in range(0,length):\n",
    "            if('datavalue' in DATA['entities'][qid]['claims'][i][j]['mainsnak'].keys() ):\n",
    "                if(DATA['entities'][qid]['claims'][i][j]['mainsnak']['datavalue']['type']=='wikibase-entityid'):\n",
    "                    Claims.append(tuple((i, DATA['entities'][qid]['claims'][i][j]['mainsnak']['datavalue']['value']['id'])))\n",
    "            \n",
    "                else:\n",
    "                    Claims.append(tuple((i,\"\")))\n",
    "\n",
    "    return Claims\n",
    "\n",
    "def evaluate_with_multiple_pid(qid1,qid2,pid_set): #general function of cosine similarity which takes two Qids.\n",
    "    prop1=qid_to_claims(qid1)\n",
    "    prop2=qid_to_claims(qid2)\n",
    "\n",
    "    embedding1=[]\n",
    "    embedding2=[]\n",
    "    count1=0\n",
    "    count2=0\n",
    "    \n",
    "    for i in range(len(prop1)):\n",
    "        if(prop1[i][0] in pid_set):\n",
    "                \n",
    "            \n",
    "                \n",
    "            pid=prop1[i][0]\n",
    "            qid=prop1[i][1]\n",
    "        \n",
    "            if count1==0:\n",
    "                embedding1=np.array(model.get_word_vector(pid))\n",
    "            else:\n",
    "                embedding1=np.add(embedding1,np.array(model.get_word_vector(pid)))\n",
    "            count1=count1+1\n",
    "            if qid!='':\n",
    "                embedding1=np.add(embedding1,np.array(model.get_word_vector(qid)))\n",
    "                count1=count1+1\n",
    "    doc_embedding1=np.divide(embedding1,count1) #document embedding of 1st property\n",
    "\n",
    "    for i in range(len(prop2)):\n",
    "        if(prop2[i][0] in pid_set):\n",
    "                \n",
    "            pid=prop2[i][0]\n",
    "            qid=prop2[i][1]\n",
    "        \n",
    "            if count2==0:\n",
    "                embedding2=np.array(model.get_word_vector(pid))\n",
    "            else:\n",
    "                embedding2=np.add(embedding2,np.array(model.get_word_vector(pid)))\n",
    "            count2=count2+1\n",
    "            if qid!='':\n",
    "                embedding2=np.add(embedding2,np.array(model.get_word_vector(qid)))\n",
    "                count2=count2+1\n",
    "    doc_embedding2=np.divide(embedding2,count2) #document embedding of 2nd property\n",
    "\n",
    "    sq1=0\n",
    "    sq2=0\n",
    "    sum=0\n",
    "    for i in range(50):\n",
    "        sum=sum+(doc_embedding1[i]*doc_embedding2[i])\n",
    "        sq1=sq1+(doc_embedding1[i]**2)\n",
    "        sq2=sq2+(doc_embedding2[i]**2)\n",
    "    sq1=sq1**0.5\n",
    "    sq2=sq2**0.5\n",
    "\n",
    "    cosine_similarity=sum/(sq1*sq2) #comparing 2 document embeddings using cosine similarity\n",
    "\n",
    "    return cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6638342133450517\n"
     ]
    }
   ],
   "source": [
    "#comparing China and india with properties- P37(official language) and P30(continent)\n",
    "\n",
    "china='Q148'\n",
    "india='Q668'\n",
    "multiple_pids=set([\"P37\",\"P30\"])\n",
    "\n",
    "print(evaluate_with_multiple_pid(china,india,multiple_pids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6638342133450517\n"
     ]
    }
   ],
   "source": [
    "#comparing japan and nepal with properties- P37(official language) and P30(continent)\n",
    "\n",
    "japan='Q17'\n",
    "nepal='Q837'\n",
    "multiple_pids=set([\"P37\",\"P30\"])\n",
    "\n",
    "print(evaluate_with_multiple_pid(china,india,multiple_pids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8748522287250468\n"
     ]
    }
   ],
   "source": [
    "#comparing China and india with properties- P47(shared border with.. ), P37(official language), and P30(continent)\n",
    "\n",
    "japan='Q17'\n",
    "india='Q668'\n",
    "multiple_pids=set([\"P47\",\"P37\",\"P30\"])\n",
    "\n",
    "print(evaluate_with_multiple_pid(china,india,multiple_pids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.022140771930297856\n"
     ]
    }
   ],
   "source": [
    "#comparing greenland and india with properties- P37(official language) and P30(continent)\n",
    "\n",
    "greenland='Q223'\n",
    "india='Q668'\n",
    "multiple_pids=set([\"P37\",\"P30\"])\n",
    "\n",
    "print(evaluate_with_multiple_pid(greenland,india,multiple_pids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015427982408300301\n"
     ]
    }
   ],
   "source": [
    "#comparing greenland and india with properties- P47(shared border with.. ), P37(official language) and P30(continent)\n",
    "\n",
    "greenland='Q223'\n",
    "india='Q668'\n",
    "multiple_pids=set([\"P37\",\"P30\",\"P47\"])\n",
    "\n",
    "print(evaluate_with_multiple_pid(greenland,india,multiple_pids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6796209228715867\n"
     ]
    }
   ],
   "source": [
    "#comparing Cristiano_Ronaldo and Neymar with properties- award received (P166), member of sports team (P54) and\n",
    "# number of matches played/races/starts (P1350)\n",
    "\n",
    "Cristiano_Ronaldo=\"Q11571\"\n",
    "Neymar=\"Q142794\"\n",
    "multiple_pids=set([\"P54\",\"P166\",\"P1350\"])\n",
    "\n",
    "print(evaluate_with_multiple_pid(Cristiano_Ronaldo,Neymar,multiple_pids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
